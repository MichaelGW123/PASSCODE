{"cells":[{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","\n","import numpy as np\n","import os\n","import time"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Length of text: 1115394 characters\n"]}],"source":["# Read, then decode for py2 compat.\n","text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n","# length of text is the number of characters in it\n","print(f'Length of text: {len(text)} characters')\n"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n"]}],"source":["# Take a look at the first 250 characters in text\n","print(text[:250])\n"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["65 unique characters\n"]}],"source":["# The unique characters in the file\n","vocab = sorted(set(text))\n","print(f'{len(vocab)} unique characters')\n"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"execution_count":55,"metadata":{},"output_type":"execute_result"}],"source":["example_texts = ['abcdefg', 'xyz']\n","\n","chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n","chars\n"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["ids_from_chars = tf.keras.layers.StringLookup(\n","    vocabulary=list(vocab), mask_token=None)\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["ids = ids_from_chars(chars)\n","ids\n"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[],"source":["chars_from_ids = tf.keras.layers.StringLookup(\n","    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["chars = chars_from_ids(ids)\n","chars\n"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["array([b'abcdefg', b'xyz'], dtype=object)"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["tf.strings.reduce_join(chars, axis=-1).numpy()\n"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[],"source":["def text_from_ids(ids):\n","  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n","all_ids\n"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[],"source":["ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["F\n","i\n","r\n","s\n","t\n"," \n","C\n","i\n","t\n","i\n"]}],"source":["for ids in ids_dataset.take(10):\n","    print(chars_from_ids(ids).numpy().decode('utf-8'))\n"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[],"source":["seq_length = 100\n"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n"," b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n"," b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n"," b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n"," b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n"," b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n"," b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n"," b'o' b'u' b' '], shape=(101,), dtype=string)\n"]}],"source":["sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n","\n","for seq in sequences.take(1):\n","  print(chars_from_ids(seq))\n"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n","b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n","b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n","b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n","b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"]}],"source":["for seq in sequences.take(5):\n","  print(text_from_ids(seq).numpy())\n"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[],"source":["def split_input_target(sequence):\n","    input_text = sequence[:-1]\n","    target_text = sequence[1:]\n","    return input_text, target_text\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/plain":["(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n"," ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["split_input_target(list(\"Tensorflow\"))\n"]},{"cell_type":"code","execution_count":70,"metadata":{},"outputs":[],"source":["dataset = sequences.map(split_input_target)\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"]}],"source":["for input_example, target_example in dataset.take(1):\n","    print(\"Input :\", text_from_ids(input_example).numpy())\n","    print(\"Target:\", text_from_ids(target_example).numpy())\n"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"data":{"text/plain":["<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset\n"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[],"source":["# Length of the vocabulary in StringLookup Layer\n","vocab_size = len(ids_from_chars.get_vocabulary())\n","\n","# The embedding dimension\n","embedding_dim = 256\n","\n","# Number of RNN units\n","rnn_units = 1024\n"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[],"source":["class MyModel(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, rnn_units):\n","    super().__init__(self)\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(rnn_units,\n","                                   return_sequences=True,\n","                                   return_state=True)\n","    self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, inputs, states=None, return_state=False, training=False):\n","    x = inputs\n","    x = self.embedding(x, training=training)\n","    if states is None:\n","      states = self.gru.get_initial_state(x)\n","    x, states = self.gru(x, initial_state=states, training=training)\n","    x = self.dense(x, training=training)\n","\n","    if return_state:\n","      return x, states\n","    else:\n","      return x\n"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["model = MyModel(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)\n"]},{"cell_type":"code","execution_count":76,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"]}],"source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"my_model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_1 (Embedding)     multiple                  16896     \n","                                                                 \n"," gru_1 (GRU)                 multiple                  3938304   \n","                                                                 \n"," dense_1 (Dense)             multiple                  67650     \n","                                                                 \n","=================================================================\n","Total params: 4022850 (15.35 MB)\n","Trainable params: 4022850 (15.35 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model.summary()\n"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[],"source":["sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/plain":["array([25, 65, 61,  7,  4, 16, 51, 58,  5, 10, 39,  2, 38, 61, 12, 53, 17,\n","       46, 38, 50, 55, 42, 24, 48, 62, 41, 57, 10, 24, 22, 27, 60, 21, 13,\n","       60, 59, 35, 54, 46, 14, 10, 47, 37, 18, 41, 18, 12, 35, 59, 47, 45,\n","       27, 56, 17, 37, 15,  5, 41, 35, 33, 35, 44, 38, 13, 30, 28, 30, 63,\n","       45, 40,  4, 11, 19, 45,  3,  3, 32, 43, 10,  0, 48,  0,  9,  5, 50,\n","       28, 18,  1,  0, 42, 41, 12, 21, 38, 17, 59, 35, 15, 12, 40])"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["sampled_indices\n"]},{"cell_type":"code","execution_count":80,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Input:\n"," b\"I will carry no crotchets: I'll re you,\\nI'll fa you; do you note me?\\n\\nFirst Musician:\\nAn you re us a\"\n","\n","Next Char Predictions:\n"," b'Lzv,$Cls&3Z Yv;nDgYkpcKiwbr3KINuH?utVogA3hXEbE;VthfNqDXB&bVTVeY?QOQxfa$:Ff!!Sd3[UNK]i[UNK].&kOE\\n[UNK]cb;HYDtVB;a'\n"]}],"source":["print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n","print()\n","print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())\n"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[],"source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n"]},{"cell_type":"code","execution_count":82,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         tf.Tensor(4.190059, shape=(), dtype=float32)\n"]}],"source":["example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", example_batch_mean_loss)\n"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[{"data":{"text/plain":["66.026695"]},"execution_count":83,"metadata":{},"output_type":"execute_result"}],"source":["tf.exp(example_batch_mean_loss).numpy()\n"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[],"source":["model.compile(optimizer='adam', loss=loss)\n"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[],"source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)\n"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[],"source":["EPOCHS = 1"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  6/172 [>.............................] - ETA: 3:22 - loss: 4.5656"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m/home/morpheus/Coding/PASSCODES/PASSCODES_RNN_debug.ipynb Cell 38\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/morpheus/Coding/PASSCODES/PASSCODES_RNN_debug.ipynb#X56sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(dataset, epochs\u001b[39m=\u001b[39;49mEPOCHS, callbacks\u001b[39m=\u001b[39;49m[checkpoint_callback])\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n","File \u001b[0;32m~/.pyenv/versions/3.9.16/envs/research/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class OneStep(tf.keras.Model):\n","  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n","    super().__init__()\n","    self.temperature = temperature\n","    self.model = model\n","    self.chars_from_ids = chars_from_ids\n","    self.ids_from_chars = ids_from_chars\n","\n","    # Create a mask to prevent \"[UNK]\" from being generated.\n","    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n","    sparse_mask = tf.SparseTensor(\n","        # Put a -inf at each bad index.\n","        values=[-float('inf')]*len(skip_ids),\n","        indices=skip_ids,\n","        # Match the shape to the vocabulary\n","        dense_shape=[len(ids_from_chars.get_vocabulary())])\n","    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n","\n","  @tf.function\n","  def generate_one_step(self, inputs, states=None):\n","    # Convert strings to token IDs.\n","    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n","    input_ids = self.ids_from_chars(input_chars).to_tensor()\n","\n","    # Run the model.\n","    # predicted_logits.shape is [batch, char, next_char_logits]\n","    predicted_logits, states = self.model(inputs=input_ids, states=states,\n","                                          return_state=True)\n","    # Only use the last prediction.\n","    predicted_logits = predicted_logits[:, -1, :]\n","    predicted_logits = predicted_logits/self.temperature\n","    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n","    predicted_logits = predicted_logits + self.prediction_mask\n","\n","    # Sample the output logits to generate token IDs.\n","    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n","    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n","\n","    # Convert from token ids to characters\n","    predicted_chars = self.chars_from_ids(predicted_ids)\n","\n","    # Return the characters and model state.\n","    return predicted_chars, states"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tf.Tensor(\n","[b\"ROMEO:\\nYor shie bime,\\nI'd nount;\\nAod, detores up.\\n\\nKO'\\nMIRGELA:\\nMoRT osh.\\nTort on frey ige ou hatay, I toblo now the bentert Sook Iibf mepor frome, blowbuss branen sto kir beath; fore thtune ardeadenas thas hot shoug,\\n\\nat thit har hee.\\n\\nTITRO:\\nYourd wet of lled?\\nBint masto coo noo ceasun;\\nHatath Uy Gus whaus woven\\nIstwirn:\\nWhe wilg lfay,\\nAnde, to murel hat er filnd I ariy hoce;.\\nSiut, foa fom era, my lowene. Holl word, the an the's wingat bey rpinghare,\\nSllors in Ro gith bows my is thy oncte,\\nAncuel thy val, and salk yors delinerkeld me, I in os will sathere sar ain co dhen lircouss, we\\nAn ant ater'.\\n\\nCLUDENUUNHAS:\\nAnd cnome corpald; at stoul nousters, bprauchess as quny now he se haon mist hod be depe sroutha!\\n\\nhill:\\nLosgipt Whoue frow!\\nHero st heute gall do hid, whou tinghin wiug;\\nBut aid you, not hear her swidh ay assins the se al ust ancengay. Gly Guat lo thair be moy huld. IN mave?' my mare, yos al best Buckt ay Thles bmors, so seram,\\n\\nIRERT:\\nOf plate, co,\\nAn shace,\\nThe:\\nSan, aid no she\"\n"," b\"ROMEO:\\nWhes rhiblor:\\nI he rat some, this tho nead hete swers famy,\\nAnd nothbud. O'd I'st ofrik his bel, tro saeeds som ulled ard, th meacr tind blall,\\nTowesn'd toret?\\nFhell bester, mato hand anmee\\nWall cewon? ithe: us oly hith how and diens, pitwisunt\\nond nos nos suella,\\nTheal\\nPost rvent sokis theaky is, lullo, baksse thaut to tom way mawecrtust het of?\\n\\nMaRUUREUS:\\nRon I gand blenchen What mevend: mese\\nAspow hos thanghanssNy shis ou ble,\\nTher! I-glond rith I AUNGEV\\nDoRI: Marery;\\nDo mw lim me camo.\\n\\nBUICENT:\\nOnow atou then caind,\\nTorc;\\nAnd, Celat, ary parthin il mis Jpavints\\nLard sot, ald ton:\\nWhenle, ou le on asecr and'd boxand.\\nEs the\\nTheree alloud.\\nWhon of tit the mime reache coo foordm.\\n\\nVURERENF:\\nO'd if she d; be wien, weorersurd I sion bnte noues swon my onot her; with tor tha ger sto coilst'l wipt is toe yourmy\\nTour, ly thenan. se thee apd an to prea derth the hat sear, methe, acns thet avende.\\n\\nLALICHAS:\\nI owp\\nAndy Laver,\\nAnd ofs my myo,\\nBowant be ho reaind homd esseroun's bonou os in\"\n"," b\"ROMEO:\\nTheie this me ro betree ails &pithe wais higf at co cay l and fawis lavesty bishirs if mefrich mum tor surd Thyend's,\\nPrehaw; wrik; foire hr urit! in tante'd moverime,\\nAf alltun:\\nRavere boicurgomen, famonte\\nSon hurk?\\nPo's:\\nWhallRapely yor Herith the havke chepreth?\\n\\nJACWENSIO:\\nTh corde.\\n\\nYOCECHANBE:\\nWhat ke toulls fient, nof ul cartt wha teve-' torbe;\\nDrach os faver erde time sosor, Youn mrtels sim efay to burce,\\nIn sull of on ulound foroeino kin! nether Egene frow and,\\nTheall.\\n\\nLUCINTINTart proed'thy,\\nThor Iviss un tied, myole;\\nTo peadtswentaat tiel tis liald foth the gorcy-blave hers poon, pershlak, soins\\nhelnes, muk heare, I pashes.\\n\\nVIONTI IS:\\nCo Whands; hathe, cwon whe dwest sutir, suel! a plake,.\\n\\nLENCINEMERTRO:\\nWay wily goom sma on terll to, ceUkeswor me? yor fae'cer athro- QBHUUTELANU:\\nI huno.\\n\\nGPEPTUYI:\\nWhar sall mireds, ristharang Gxewere's:\\nMatt I woru youf in the best?\\n\\nGOIN:\\nSy surt reckime.\\n\\nCARUTIT:\\nNhat! is wiml At qushpeechest gwave moold whe foupr my hols maves falle\"\n"," b\"ROMEO:\\nCo fired.\\n\\nSINIRAO:\\nAn med,\\nThan ton, my sowhe wor the he now is onte bleenin\\nWo lustir\\nNordurun; fors usie; nee wurerive\\nbe rrate with weare.\\n\\nMaMSOREN:\\nFit, and In ma tom or awhstrabenthoud I durear, fortan, fon tha bonat wot raingey int I hat here the? Thos by.\\n\\nMIOKI\\nMINAMA:\\nO I rie Thout san dionf yoprorf, QoxPreres. \\nLANPERY\\nARILE:\\nDor modin Whats wond pawith lo toumse hare go bo com tor spommut.\\n\\nCURCINENERE:\\nThe thim hy,\\nOpucmur wint the d the wive\\ndre hyou best ke to baberap?\\nTlo ipearentang,\\nAnd wigh at to bow mest Mlt se I tre ha dod dead tish efeak\\nBithemom;\\nForem, foult it tiss jostnou; cerer, t eatho,\\nThale And arille, had abme band but, tho day,\\nHy, the sat prisere\\nheer's whou te himld int mpearkendurp somy?\\nNoth the s it mord'de,\\nButhis miencen at whim yous at har sorere wigcor at moln wang mencartigh\\nAr mer forcay ous and mondter's,\\nAnd bast shou ie alld beray, at thate sowed hay; uret and ar te kla ma at frech; age in sh weazes mebreik; rowsp, and e thte nipllens fur\"\n"," b\"ROMEO:\\nLove, and lactheos platt che bowtarde higed thee ow thes ciney lood,\\nThe ham ed Panceld't eor frlast dour:\\nAnd copgate be;\\nBure, no oute mary i' theit hay thet all dou. Low ip dat asw; aw hare too ould sitherf?\\n\\nLARTECACETTI:\\nO fare,.\\nTo bard tor, to gow cerereruchingho'gis my your do coame bu preaser; of parith of weld: lik shairtime if wrole nom than uncon thill, ins asall dicods, 'll meind.\\n\\nFroRLI:\\nWhas seat th ce in.\\n\\nAId LORCIBK:\\nOre none I tw leen st leron nith, wod,\\nMathun tow, is fay Lo\\ngarnte thous the koper:\\nWerles do fromed fout bpe thow\\nAh dou parod! ser pope;\\nTher ally\\nThing:\\nThit on ghath meall'se Hafear\\nTo hith be d aspmat ines.\\n\\nPEKANOUWe I spre\\nAnd kin thikjun; ande toled cust ily blo;\\nAnd with de thos bistly hair hord han the go lith eor tpem;\\nThat thit y of mabus\\nBlaks, I andes cheer whas she will so-may, ghe pere?\\nHy k canotr wie hould tro he, bed zis mo bbod thes mene sing?\\nBut anf Whattar ghy Buste wo, furs of dor welderere'st and sty uf chos walen on trall E fe\"], shape=(5,), dtype=string) \n","\n","________________________________________________________________________________\n","\n","Run time: 2.462477445602417\n"]}],"source":["start = time.time()\n","states = None\n","next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n","result = [next_char]\n","\n","for n in range(1000):\n","  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n","  result.append(next_char)\n","\n","result = tf.strings.join(result)\n","end = time.time()\n","print(result, '\\n\\n' + '_'*80)\n","print('\\nRun time:', end - start)\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
